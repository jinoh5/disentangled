{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jinoh5/disentangled/blob/main/run_multi_task.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "sdIM7UVnyZqo"
      },
      "outputs": [],
      "source": [
        "import scipy\n",
        "from scipy import stats\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "# Torch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset, Subset\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBSun9f9zqtP"
      },
      "source": [
        "## Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "p5haXXz6zsf0"
      },
      "outputs": [],
      "source": [
        "sigma = 1\n",
        "N = 20 # 20 dimensional space\n",
        "T = 100\n",
        "numCond = 4\n",
        "noise_var = 2 # may increase this to 2\n",
        "\n",
        "input_dim = 20\n",
        "output_dim = 2\n",
        "learning_rate = 0.001\n",
        "batch_size = 20\n",
        "hidden_dim = input_dim * 2\n",
        "exp_num = 3\n",
        "num_epochs = 200\n",
        "iter_num = 30\n",
        "\n",
        "beta1 = 1\n",
        "beta2 = 0\n",
        "beta3 = 1\n",
        "beta4 = 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgC8jGC7yytY"
      },
      "source": [
        "## INPUT set up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Wr2w_oaMyx5G"
      },
      "outputs": [],
      "source": [
        "# Disentangled Points\n",
        "cond = np.zeros((4,2))\n",
        "cond[0,:] = [1,1]\n",
        "cond[1,:] = [-1,1]\n",
        "cond[2,:] = [-1,-1]\n",
        "cond[3,:] = [1,-1]\n",
        "\n",
        "cond = cond.T\n",
        "\n",
        "# Project the data onto the 20-D space\n",
        "projection = np.zeros((numCond,T,N))\n",
        "W = stats.norm.rvs(loc=0, scale=sigma, size=[N,2])\n",
        "for i in range(T): # T = 100 trials\n",
        "    projection[0,i,:] = W @ cond[:,0] # V (N x 1) = W (N x 2) * I (2 x 1)\n",
        "    projection[1,i,:] = W @ cond[:,1]\n",
        "    projection[2,i,:] = W @ cond[:,2]\n",
        "    projection[3,i,:] = W @ cond[:,3]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NU7dxFGNy1Sc"
      },
      "source": [
        "## Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "WzkMgqFuy2cU"
      },
      "outputs": [],
      "source": [
        "def create_input(projection, noise_var):\n",
        "  # Create noise\n",
        "  noise_matrix = np.random.normal(loc=0, scale=noise_var, size=projection.shape)\n",
        "\n",
        "  # Add noise\n",
        "  input_w_noise = projection + noise_matrix\n",
        "\n",
        "  # Reshape to create 400 x 20\n",
        "  input_dis = np.vstack((input_w_noise[0,:,:], input_w_noise[1,:,:], input_w_noise[2,:,:], input_w_noise[3,:,:]))\n",
        "\n",
        "  # Experiment conditions\n",
        "  org_cond = np.zeros((4,2))\n",
        "  org_cond[1,:] = [1,0]\n",
        "  org_cond[2,:] = [1,1]\n",
        "  org_cond[3,:] = [0,1]\n",
        "\n",
        "  task1 = org_cond[:,0]\n",
        "  task2 = org_cond[:,1]\n",
        "  xor = np.sum(org_cond,axis=1)%2\n",
        "\n",
        "  # Classes\n",
        "  task1_class = np.repeat(task1, T)\n",
        "  task2_class = np.repeat(task2, T)\n",
        "  xor_class = np.repeat(xor, T)\n",
        "\n",
        "  classes = np.zeros((numCond*T, 3))\n",
        "  classes[:,0] = task1_class\n",
        "  classes[:,1] = task2_class\n",
        "  classes[:,2] = xor_class\n",
        "\n",
        "  return input_dis, classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "dCZmLoj23qJD"
      },
      "outputs": [],
      "source": [
        "# Losses\n",
        "def custom_loss(output, targets, sparsity, beta1, beta2, PR, beta3): # PR_connect, beta4\n",
        "  '''\n",
        "  Custom loss function\n",
        "  '''\n",
        "  criterion = nn.CrossEntropyLoss() # first task\n",
        "  crossEntropy = criterion(output, targets)\n",
        "\n",
        "  totalLoss = beta1 * criterion(output, targets) + beta2 * sparsity + beta3 * PR #+ beta4 * PR_connect\n",
        "  return crossEntropy, totalLoss\n",
        "\n",
        "def L1_norm(hidden_output):\n",
        "  l1_norm = torch.mean(torch.abs(hidden_output)) # gives me a simple number\n",
        "  return l1_norm\n",
        "\n",
        "def PR_norm(hidden_output):\n",
        "  cov_matrix = torch.cov(hidden_output)\n",
        "  eigval, _ = torch.linalg.eigh(cov_matrix)\n",
        "  numerator = torch.sum(eigval) ** 2\n",
        "  denominator = torch.sum(eigval ** 2)\n",
        "  participation_ratio = numerator / denominator\n",
        "  return participation_ratio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "jm7Mb6964m4p"
      },
      "outputs": [],
      "source": [
        "# Model (nonlinear classifier)\n",
        "class Simple_Nonlin(nn.Module):\n",
        "\n",
        "  def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "    super(Simple_Nonlin, self).__init__()\n",
        "    self.input_layer = nn.Linear(input_dim, hidden_dim)\n",
        "    self.hidden_layer = nn.Linear(hidden_dim, output_dim) # here, I can add noise to make noises in the hidden layer\n",
        "\n",
        "  def forward(self, x):\n",
        "    x_h = F.relu(self.input_layer(x)) # Applying ReLU activation after input_layer\n",
        "    output = self.hidden_layer(x_h)\n",
        "    return x_h, output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "x_NC0SeIyh-3"
      },
      "outputs": [],
      "source": [
        "def calculate_centroid(points):\n",
        "   # INPUT: PCAed 3D points 100 x 3 so that it can be 1 x 3\n",
        "    centroid_x = np.mean(points[:, 0])\n",
        "    centroid_y = np.mean(points[:, 1])\n",
        "    centroid_z = np.mean(points[:, 2])\n",
        "\n",
        "    return [centroid_x, centroid_y, centroid_z]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvzaCf505Iac"
      },
      "source": [
        "## Run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "-nca7QM22ECi"
      },
      "outputs": [],
      "source": [
        "train_input, train_classes = create_input(projection, noise_var)\n",
        "test_input, train_classes = create_input(projection, noise_var)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "0-nd7kGQ5Xad"
      },
      "outputs": [],
      "source": [
        "trainI = torch.tensor(train_input, dtype=torch.float32)\n",
        "trainT = torch.tensor(train_classes, dtype=torch.long)\n",
        "\n",
        "testI = torch.tensor(test_input, dtype = torch.float32)\n",
        "testT = torch.tensor(train_classes, dtype = torch.long)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "g4fCfyqPIIKQ"
      },
      "outputs": [],
      "source": [
        "exp_list = [[0,0],\n",
        "            [0,1],\n",
        "            [0,2],\n",
        "            [1,0],\n",
        "            [1,1],\n",
        "            [1,2],\n",
        "            [2,0],\n",
        "            [2,1],\n",
        "            [2,2]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ADTDVfWcrbqU"
      },
      "outputs": [],
      "source": [
        "pca_dict = {i: np.zeros((iter_num, 400, 3)) for i in range(len(exp_list))}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RIIV3LnbnKYz",
        "outputId": "a44cf6ac-672a-4d03-8082-1537cd1b12db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iter 0\n",
            "train # 0\n",
            "test # 0\n",
            "avg_acc_per_exp 0.9925249999999997\n",
            "train # 0\n",
            "test # 1\n",
            "avg_acc_per_exp 0.5040999999999998\n",
            "train # 0\n",
            "test # 2\n",
            "avg_acc_per_exp 0.5006499999999999\n",
            "train # 1\n",
            "test # 0\n",
            "avg_acc_per_exp 0.5035875\n",
            "train # 1\n",
            "test # 1\n",
            "avg_acc_per_exp 0.9844125000000002\n",
            "train # 1\n",
            "test # 2\n",
            "avg_acc_per_exp 0.5032874999999999\n",
            "train # 2\n",
            "test # 0\n",
            "avg_acc_per_exp 0.5018375\n",
            "train # 2\n",
            "test # 1\n",
            "avg_acc_per_exp 0.49707499999999993\n",
            "train # 2\n",
            "test # 2\n",
            "avg_acc_per_exp 0.9802625\n",
            "Epoch 200 took 153.20593571662903 seconds\n",
            "iter 1\n",
            "train # 0\n",
            "test # 0\n",
            "avg_acc_per_exp 0.9931874999999998\n",
            "train # 0\n",
            "test # 1\n",
            "avg_acc_per_exp 0.501625\n",
            "train # 0\n",
            "test # 2\n",
            "avg_acc_per_exp 0.5013124999999998\n",
            "train # 1\n",
            "test # 0\n",
            "avg_acc_per_exp 0.49492500000000006\n",
            "train # 1\n",
            "test # 1\n",
            "avg_acc_per_exp 0.9827499999999999\n",
            "train # 1\n",
            "test # 2\n",
            "avg_acc_per_exp 0.5021874999999999\n",
            "train # 2\n",
            "test # 0\n",
            "avg_acc_per_exp 0.5026499999999999\n",
            "train # 2\n",
            "test # 1\n",
            "avg_acc_per_exp 0.4992874999999998\n",
            "train # 2\n",
            "test # 2\n",
            "avg_acc_per_exp 0.9866749999999999\n",
            "Epoch 200 took 131.5083236694336 seconds\n",
            "iter 2\n",
            "train # 0\n",
            "test # 0\n",
            "avg_acc_per_exp 0.9867624999999998\n",
            "train # 0\n",
            "test # 1\n",
            "avg_acc_per_exp 0.4980874999999999\n",
            "train # 0\n",
            "test # 2\n",
            "avg_acc_per_exp 0.5008624999999999\n",
            "train # 1\n",
            "test # 0\n",
            "avg_acc_per_exp 0.4974625\n",
            "train # 1\n",
            "test # 1\n",
            "avg_acc_per_exp 0.979975\n",
            "train # 1\n",
            "test # 2\n",
            "avg_acc_per_exp 0.50595\n",
            "train # 2\n",
            "test # 0\n",
            "avg_acc_per_exp 0.5002\n",
            "train # 2\n",
            "test # 1\n",
            "avg_acc_per_exp 0.5025624999999998\n",
            "train # 2\n",
            "test # 2\n",
            "avg_acc_per_exp 0.9716874999999999\n",
            "Epoch 200 took 129.24626278877258 seconds\n",
            "iter 3\n",
            "train # 0\n",
            "test # 0\n",
            "avg_acc_per_exp 0.9933999999999997\n",
            "train # 0\n",
            "test # 1\n",
            "avg_acc_per_exp 0.499375\n",
            "train # 0\n",
            "test # 2\n",
            "avg_acc_per_exp 0.5010249999999999\n",
            "train # 1\n",
            "test # 0\n",
            "avg_acc_per_exp 0.497025\n",
            "train # 1\n",
            "test # 1\n",
            "avg_acc_per_exp 0.9878125000000001\n",
            "train # 1\n",
            "test # 2\n",
            "avg_acc_per_exp 0.5045000000000001\n",
            "train # 2\n",
            "test # 0\n",
            "avg_acc_per_exp 0.5005749999999999\n",
            "train # 2\n",
            "test # 1\n",
            "avg_acc_per_exp 0.4993374999999999\n",
            "train # 2\n",
            "test # 2\n",
            "avg_acc_per_exp 0.9767\n",
            "Epoch 200 took 128.26018357276917 seconds\n",
            "iter 4\n",
            "train # 0\n",
            "test # 0\n",
            "avg_acc_per_exp 0.9936249999999999\n",
            "train # 0\n",
            "test # 1\n",
            "avg_acc_per_exp 0.500075\n",
            "train # 0\n",
            "test # 2\n",
            "avg_acc_per_exp 0.5011624999999998\n",
            "train # 1\n",
            "test # 0\n",
            "avg_acc_per_exp 0.4949375\n",
            "train # 1\n",
            "test # 1\n",
            "avg_acc_per_exp 0.979775\n",
            "train # 1\n",
            "test # 2\n",
            "avg_acc_per_exp 0.5041499999999999\n",
            "train # 2\n",
            "test # 0\n",
            "avg_acc_per_exp 0.5044624999999998\n",
            "train # 2\n",
            "test # 1\n",
            "avg_acc_per_exp 0.50235\n",
            "train # 2\n",
            "test # 2\n",
            "avg_acc_per_exp 0.9800874999999999\n",
            "Epoch 200 took 129.07496213912964 seconds\n",
            "iter 5\n",
            "train # 0\n",
            "test # 0\n",
            "avg_acc_per_exp 0.9892874999999998\n",
            "train # 0\n",
            "test # 1\n",
            "avg_acc_per_exp 0.5028874999999998\n",
            "train # 0\n",
            "test # 2\n",
            "avg_acc_per_exp 0.5001375\n",
            "train # 1\n",
            "test # 0\n",
            "avg_acc_per_exp 0.5028374999999999\n",
            "train # 1\n",
            "test # 1\n",
            "avg_acc_per_exp 0.9921125000000004\n",
            "train # 1\n",
            "test # 2\n",
            "avg_acc_per_exp 0.502025\n",
            "train # 2\n",
            "test # 0\n",
            "avg_acc_per_exp 0.50115\n",
            "train # 2\n",
            "test # 1\n",
            "avg_acc_per_exp 0.49737499999999996\n",
            "train # 2\n",
            "test # 2\n",
            "avg_acc_per_exp 0.9740625000000002\n",
            "Epoch 200 took 131.21650886535645 seconds\n",
            "iter 6\n",
            "train # 0\n",
            "test # 0\n",
            "avg_acc_per_exp 0.9921374999999998\n",
            "train # 0\n",
            "test # 1\n",
            "avg_acc_per_exp 0.4959125\n",
            "train # 0\n",
            "test # 2\n",
            "avg_acc_per_exp 0.5008499999999999\n",
            "train # 1\n",
            "test # 0\n",
            "avg_acc_per_exp 0.5004999999999998\n",
            "train # 1\n",
            "test # 1\n",
            "avg_acc_per_exp 0.9769500000000002\n",
            "train # 1\n",
            "test # 2\n",
            "avg_acc_per_exp 0.5050625\n",
            "train # 2\n",
            "test # 0\n",
            "avg_acc_per_exp 0.4947\n",
            "train # 2\n",
            "test # 1\n",
            "avg_acc_per_exp 0.5029499999999999\n",
            "train # 2\n",
            "test # 2\n",
            "avg_acc_per_exp 0.98015\n",
            "Epoch 200 took 133.68004727363586 seconds\n",
            "iter 7\n",
            "train # 0\n",
            "test # 0\n",
            "avg_acc_per_exp 0.9929749999999998\n",
            "train # 0\n",
            "test # 1\n",
            "avg_acc_per_exp 0.5032999999999999\n",
            "train # 0\n",
            "test # 2\n",
            "avg_acc_per_exp 0.5042624999999998\n",
            "train # 1\n",
            "test # 0\n",
            "avg_acc_per_exp 0.49471249999999983\n",
            "train # 1\n",
            "test # 1\n",
            "avg_acc_per_exp 0.9869\n",
            "train # 1\n",
            "test # 2\n",
            "avg_acc_per_exp 0.5033124999999999\n",
            "train # 2\n",
            "test # 0\n",
            "avg_acc_per_exp 0.4984999999999999\n",
            "train # 2\n",
            "test # 1\n",
            "avg_acc_per_exp 0.5015999999999999\n",
            "train # 2\n",
            "test # 2\n",
            "avg_acc_per_exp 0.97835\n",
            "Epoch 200 took 133.0408797264099 seconds\n",
            "iter 8\n",
            "train # 0\n",
            "test # 0\n",
            "avg_acc_per_exp 0.9883125000000001\n",
            "train # 0\n",
            "test # 1\n",
            "avg_acc_per_exp 0.50125\n",
            "train # 0\n",
            "test # 2\n",
            "avg_acc_per_exp 0.5022999999999997\n",
            "train # 1\n",
            "test # 0\n",
            "avg_acc_per_exp 0.49926249999999994\n",
            "train # 1\n",
            "test # 1\n",
            "avg_acc_per_exp 0.986775\n",
            "train # 1\n",
            "test # 2\n",
            "avg_acc_per_exp 0.498625\n",
            "train # 2\n",
            "test # 0\n",
            "avg_acc_per_exp 0.49499999999999994\n",
            "train # 2\n",
            "test # 1\n",
            "avg_acc_per_exp 0.5034249999999999\n",
            "train # 2\n",
            "test # 2\n",
            "avg_acc_per_exp 0.9802874999999998\n",
            "Epoch 200 took 133.23435997962952 seconds\n",
            "iter 9\n",
            "train # 0\n",
            "test # 0\n",
            "avg_acc_per_exp 0.9935999999999998\n",
            "train # 0\n",
            "test # 1\n",
            "avg_acc_per_exp 0.498125\n",
            "train # 0\n",
            "test # 2\n",
            "avg_acc_per_exp 0.4988375\n",
            "train # 1\n",
            "test # 0\n",
            "avg_acc_per_exp 0.49613749999999995\n",
            "train # 1\n",
            "test # 1\n",
            "avg_acc_per_exp 0.9871875000000001\n",
            "train # 1\n",
            "test # 2\n",
            "avg_acc_per_exp 0.5052124999999998\n",
            "train # 2\n",
            "test # 0\n",
            "avg_acc_per_exp 0.5069499999999999\n",
            "train # 2\n",
            "test # 1\n",
            "avg_acc_per_exp 0.5032374999999999\n",
            "train # 2\n",
            "test # 2\n",
            "avg_acc_per_exp 0.9823749999999998\n",
            "Epoch 200 took 132.33679914474487 seconds\n",
            "iter 10\n",
            "train # 0\n",
            "test # 0\n",
            "avg_acc_per_exp 0.9880374999999998\n",
            "train # 0\n",
            "test # 1\n",
            "avg_acc_per_exp 0.5023125\n",
            "train # 0\n",
            "test # 2\n",
            "avg_acc_per_exp 0.5008625\n",
            "train # 1\n",
            "test # 0\n",
            "avg_acc_per_exp 0.489525\n",
            "train # 1\n",
            "test # 1\n",
            "avg_acc_per_exp 0.9875499999999999\n",
            "train # 1\n",
            "test # 2\n",
            "avg_acc_per_exp 0.49999999999999994\n",
            "train # 2\n",
            "test # 0\n",
            "avg_acc_per_exp 0.5035624999999999\n",
            "train # 2\n",
            "test # 1\n",
            "avg_acc_per_exp 0.502025\n",
            "train # 2\n",
            "test # 2\n",
            "avg_acc_per_exp 0.9836249999999999\n",
            "Epoch 200 took 134.73525953292847 seconds\n",
            "iter 11\n",
            "train # 0\n",
            "test # 0\n",
            "avg_acc_per_exp 0.9915624999999999\n",
            "train # 0\n",
            "test # 1\n",
            "avg_acc_per_exp 0.5039374999999998\n",
            "train # 0\n",
            "test # 2\n",
            "avg_acc_per_exp 0.5001125\n",
            "train # 1\n",
            "test # 0\n",
            "avg_acc_per_exp 0.5015999999999999\n",
            "train # 1\n",
            "test # 1\n",
            "avg_acc_per_exp 0.987275\n",
            "train # 1\n",
            "test # 2\n",
            "avg_acc_per_exp 0.5028124999999999\n",
            "train # 2\n",
            "test # 0\n",
            "avg_acc_per_exp 0.5025375\n",
            "train # 2\n",
            "test # 1\n",
            "avg_acc_per_exp 0.49999999999999983\n",
            "train # 2\n",
            "test # 2\n",
            "avg_acc_per_exp 0.9697999999999999\n",
            "Epoch 200 took 134.11629438400269 seconds\n",
            "iter 12\n",
            "train # 0\n",
            "test # 0\n",
            "avg_acc_per_exp 0.9901749999999998\n",
            "train # 0\n",
            "test # 1\n",
            "avg_acc_per_exp 0.5039124999999998\n",
            "train # 0\n",
            "test # 2\n",
            "avg_acc_per_exp 0.5019999999999998\n",
            "train # 1\n",
            "test # 0\n",
            "avg_acc_per_exp 0.5013624999999998\n",
            "train # 1\n",
            "test # 1\n",
            "avg_acc_per_exp 0.9863250000000002\n",
            "train # 1\n",
            "test # 2\n",
            "avg_acc_per_exp 0.503825\n",
            "train # 2\n",
            "test # 0\n",
            "avg_acc_per_exp 0.5047749999999999\n",
            "train # 2\n",
            "test # 1\n",
            "avg_acc_per_exp 0.5111749999999999\n",
            "train # 2\n",
            "test # 2\n",
            "avg_acc_per_exp 0.9687749999999999\n",
            "Epoch 200 took 134.73564171791077 seconds\n",
            "iter 13\n",
            "train # 0\n",
            "test # 0\n",
            "avg_acc_per_exp 0.9931999999999997\n",
            "train # 0\n",
            "test # 1\n",
            "avg_acc_per_exp 0.50015\n",
            "train # 0\n",
            "test # 2\n",
            "avg_acc_per_exp 0.5025749999999998\n",
            "train # 1\n",
            "test # 0\n",
            "avg_acc_per_exp 0.4908625000000001\n",
            "train # 1\n",
            "test # 1\n",
            "avg_acc_per_exp 0.9885999999999998\n",
            "train # 1\n",
            "test # 2\n",
            "avg_acc_per_exp 0.5038124999999998\n",
            "train # 2\n",
            "test # 0\n",
            "avg_acc_per_exp 0.5083125\n",
            "train # 2\n",
            "test # 1\n",
            "avg_acc_per_exp 0.4966874999999999\n",
            "train # 2\n",
            "test # 2\n",
            "avg_acc_per_exp 0.9833625\n",
            "Epoch 200 took 131.01327872276306 seconds\n",
            "iter 14\n",
            "train # 0\n",
            "test # 0\n",
            "avg_acc_per_exp 0.9933374999999998\n",
            "train # 0\n",
            "test # 1\n",
            "avg_acc_per_exp 0.5053249999999998\n",
            "train # 0\n",
            "test # 2\n",
            "avg_acc_per_exp 0.5014374999999999\n",
            "train # 1\n",
            "test # 0\n",
            "avg_acc_per_exp 0.5000625\n",
            "train # 1\n",
            "test # 1\n",
            "avg_acc_per_exp 0.982575\n",
            "train # 1\n",
            "test # 2\n",
            "avg_acc_per_exp 0.5080375\n",
            "train # 2\n",
            "test # 0\n",
            "avg_acc_per_exp 0.49992499999999995\n",
            "train # 2\n",
            "test # 1\n",
            "avg_acc_per_exp 0.49908749999999996\n",
            "train # 2\n",
            "test # 2\n",
            "avg_acc_per_exp 0.9801000000000002\n",
            "Epoch 200 took 130.47868752479553 seconds\n",
            "iter 15\n",
            "train # 0\n",
            "test # 0\n",
            "avg_acc_per_exp 0.9943499999999997\n",
            "train # 0\n",
            "test # 1\n",
            "avg_acc_per_exp 0.50185\n",
            "train # 0\n",
            "test # 2\n",
            "avg_acc_per_exp 0.5022874999999999\n",
            "train # 1\n",
            "test # 0\n",
            "avg_acc_per_exp 0.49918749999999995\n",
            "train # 1\n",
            "test # 1\n",
            "avg_acc_per_exp 0.98565\n",
            "train # 1\n",
            "test # 2\n",
            "avg_acc_per_exp 0.4988249999999999\n",
            "train # 2\n",
            "test # 0\n",
            "avg_acc_per_exp 0.5049874999999999\n",
            "train # 2\n",
            "test # 1\n",
            "avg_acc_per_exp 0.49797499999999983\n",
            "train # 2\n",
            "test # 2\n",
            "avg_acc_per_exp 0.9809125000000001\n",
            "Epoch 200 took 128.88263845443726 seconds\n",
            "iter 16\n",
            "train # 0\n",
            "test # 0\n",
            "avg_acc_per_exp 0.9877624999999999\n",
            "train # 0\n",
            "test # 1\n",
            "avg_acc_per_exp 0.5021499999999999\n",
            "train # 0\n",
            "test # 2\n",
            "avg_acc_per_exp 0.5009625\n",
            "train # 1\n",
            "test # 0\n",
            "avg_acc_per_exp 0.5085375000000001\n",
            "train # 1\n",
            "test # 1\n",
            "avg_acc_per_exp 0.9780375000000001\n",
            "train # 1\n",
            "test # 2\n",
            "avg_acc_per_exp 0.5011624999999998\n",
            "train # 2\n",
            "test # 0\n",
            "avg_acc_per_exp 0.5043\n",
            "train # 2\n",
            "test # 1\n",
            "avg_acc_per_exp 0.5088874999999999\n",
            "train # 2\n",
            "test # 2\n",
            "avg_acc_per_exp 0.9739500000000001\n",
            "Epoch 200 took 129.2970278263092 seconds\n",
            "iter 17\n",
            "train # 0\n",
            "test # 0\n",
            "avg_acc_per_exp 0.990675\n",
            "train # 0\n",
            "test # 1\n",
            "avg_acc_per_exp 0.5058749999999997\n",
            "train # 0\n",
            "test # 2\n",
            "avg_acc_per_exp 0.49973749999999995\n",
            "train # 1\n",
            "test # 0\n",
            "avg_acc_per_exp 0.4908374999999999\n",
            "train # 1\n",
            "test # 1\n",
            "avg_acc_per_exp 0.98375\n",
            "train # 1\n",
            "test # 2\n",
            "avg_acc_per_exp 0.4985124999999999\n",
            "train # 2\n",
            "test # 0\n",
            "avg_acc_per_exp 0.4981499999999999\n",
            "train # 2\n",
            "test # 1\n",
            "avg_acc_per_exp 0.5007375\n",
            "train # 2\n",
            "test # 2\n",
            "avg_acc_per_exp 0.9799125000000002\n",
            "Epoch 200 took 132.26209568977356 seconds\n",
            "iter 18\n",
            "train # 0\n",
            "test # 0\n",
            "avg_acc_per_exp 0.9942624999999998\n",
            "train # 0\n",
            "test # 1\n",
            "avg_acc_per_exp 0.49757499999999993\n",
            "train # 0\n",
            "test # 2\n",
            "avg_acc_per_exp 0.5017374999999997\n",
            "train # 1\n",
            "test # 0\n",
            "avg_acc_per_exp 0.4972625\n",
            "train # 1\n",
            "test # 1\n",
            "avg_acc_per_exp 0.98685\n",
            "train # 1\n",
            "test # 2\n",
            "avg_acc_per_exp 0.49991249999999987\n",
            "train # 2\n",
            "test # 0\n",
            "avg_acc_per_exp 0.5018125\n",
            "train # 2\n",
            "test # 1\n",
            "avg_acc_per_exp 0.5024999999999998\n",
            "train # 2\n",
            "test # 2\n",
            "avg_acc_per_exp 0.9745250000000002\n",
            "Epoch 200 took 131.85654401779175 seconds\n",
            "iter 19\n",
            "train # 0\n",
            "test # 0\n",
            "avg_acc_per_exp 0.9927874999999997\n",
            "train # 0\n",
            "test # 1\n",
            "avg_acc_per_exp 0.5010249999999999\n",
            "train # 0\n",
            "test # 2\n",
            "avg_acc_per_exp 0.5037249999999998\n",
            "train # 1\n",
            "test # 0\n",
            "avg_acc_per_exp 0.5100625\n",
            "train # 1\n",
            "test # 1\n",
            "avg_acc_per_exp 0.9863624999999999\n",
            "train # 1\n",
            "test # 2\n",
            "avg_acc_per_exp 0.5044124999999998\n",
            "train # 2\n",
            "test # 0\n",
            "avg_acc_per_exp 0.49357500000000004\n",
            "train # 2\n",
            "test # 1\n",
            "avg_acc_per_exp 0.508975\n",
            "train # 2\n",
            "test # 2\n",
            "avg_acc_per_exp 0.9716\n",
            "Epoch 200 took 128.31204676628113 seconds\n",
            "iter 20\n",
            "train # 0\n",
            "test # 0\n",
            "avg_acc_per_exp 0.9946624999999998\n",
            "train # 0\n",
            "test # 1\n",
            "avg_acc_per_exp 0.4983749999999999\n",
            "train # 0\n",
            "test # 2\n",
            "avg_acc_per_exp 0.5000249999999999\n",
            "train # 1\n",
            "test # 0\n",
            "avg_acc_per_exp 0.5049749999999998\n",
            "train # 1\n",
            "test # 1\n",
            "avg_acc_per_exp 0.9901625000000002\n",
            "train # 1\n",
            "test # 2\n",
            "avg_acc_per_exp 0.49853749999999997\n",
            "train # 2\n",
            "test # 0\n",
            "avg_acc_per_exp 0.5003624999999999\n",
            "train # 2\n",
            "test # 1\n",
            "avg_acc_per_exp 0.5107250000000001\n",
            "train # 2\n",
            "test # 2\n",
            "avg_acc_per_exp 0.9795625000000001\n",
            "Epoch 200 took 130.67880725860596 seconds\n",
            "iter 21\n",
            "train # 0\n",
            "test # 0\n",
            "avg_acc_per_exp 0.9922999999999998\n",
            "train # 0\n",
            "test # 1\n",
            "avg_acc_per_exp 0.49988750000000004\n",
            "train # 0\n",
            "test # 2\n",
            "avg_acc_per_exp 0.5016624999999999\n",
            "train # 1\n",
            "test # 0\n",
            "avg_acc_per_exp 0.5033375\n",
            "train # 1\n",
            "test # 1\n",
            "avg_acc_per_exp 0.9870625\n",
            "train # 1\n",
            "test # 2\n",
            "avg_acc_per_exp 0.49103750000000007\n",
            "train # 2\n",
            "test # 0\n",
            "avg_acc_per_exp 0.5018249999999999\n",
            "train # 2\n",
            "test # 1\n",
            "avg_acc_per_exp 0.5081\n",
            "train # 2\n",
            "test # 2\n",
            "avg_acc_per_exp 0.9620625000000003\n",
            "Epoch 200 took 130.80003595352173 seconds\n",
            "iter 22\n",
            "train # 0\n",
            "test # 0\n",
            "avg_acc_per_exp 0.9861124999999998\n",
            "train # 0\n",
            "test # 1\n",
            "avg_acc_per_exp 0.5013875\n",
            "train # 0\n",
            "test # 2\n",
            "avg_acc_per_exp 0.5006375\n",
            "train # 1\n",
            "test # 0\n",
            "avg_acc_per_exp 0.49701249999999986\n",
            "train # 1\n",
            "test # 1\n",
            "avg_acc_per_exp 0.9850375\n",
            "train # 1\n",
            "test # 2\n",
            "avg_acc_per_exp 0.5037375000000001\n",
            "train # 2\n",
            "test # 0\n",
            "avg_acc_per_exp 0.5002874999999999\n",
            "train # 2\n",
            "test # 1\n",
            "avg_acc_per_exp 0.5050125\n",
            "train # 2\n",
            "test # 2\n",
            "avg_acc_per_exp 0.9802125\n",
            "Epoch 200 took 129.01418900489807 seconds\n",
            "iter 23\n",
            "train # 0\n",
            "test # 0\n",
            "avg_acc_per_exp 0.9921874999999999\n",
            "train # 0\n",
            "test # 1\n",
            "avg_acc_per_exp 0.49975\n",
            "train # 0\n",
            "test # 2\n",
            "avg_acc_per_exp 0.5004625\n",
            "train # 1\n",
            "test # 0\n",
            "avg_acc_per_exp 0.5032374999999998\n",
            "train # 1\n",
            "test # 1\n",
            "avg_acc_per_exp 0.9902249999999998\n",
            "train # 1\n",
            "test # 2\n",
            "avg_acc_per_exp 0.504025\n",
            "train # 2\n",
            "test # 0\n",
            "avg_acc_per_exp 0.5051749999999999\n",
            "train # 2\n",
            "test # 1\n",
            "avg_acc_per_exp 0.5006124999999999\n",
            "train # 2\n",
            "test # 2\n",
            "avg_acc_per_exp 0.965025\n",
            "Epoch 200 took 128.74682688713074 seconds\n",
            "iter 24\n",
            "train # 0\n",
            "test # 0\n",
            "avg_acc_per_exp 0.9935124999999997\n",
            "train # 0\n",
            "test # 1\n",
            "avg_acc_per_exp 0.5\n",
            "train # 0\n",
            "test # 2\n",
            "avg_acc_per_exp 0.5027499999999998\n",
            "train # 1\n",
            "test # 0\n",
            "avg_acc_per_exp 0.497525\n",
            "train # 1\n",
            "test # 1\n",
            "avg_acc_per_exp 0.9835625\n",
            "train # 1\n",
            "test # 2\n",
            "avg_acc_per_exp 0.5027375\n",
            "train # 2\n",
            "test # 0\n",
            "avg_acc_per_exp 0.5041875\n",
            "train # 2\n",
            "test # 1\n",
            "avg_acc_per_exp 0.5048999999999999\n",
            "train # 2\n",
            "test # 2\n"
          ]
        }
      ],
      "source": [
        "# Create shuffled indices\n",
        "indices = torch.randperm(len(trainI))\n",
        "\n",
        "# Shuffled train and test\n",
        "shuffled_trainI = trainI[indices,:]\n",
        "shuffled_trainT = trainT[indices,:]\n",
        "\n",
        "shuffled_testI = testI[indices,:]\n",
        "shuffled_testT = testT[indices,:]\n",
        "\n",
        "total_accuracies = np.zeros((iter_num,len(exp_list))) # you need iternum\n",
        "\n",
        "for iter in range(iter_num): # 1. LOOP FOR ITERATION OF THE EXPERIMENT\n",
        "  print(\"iter\", iter)\n",
        "  start_time = time.time()\n",
        "\n",
        "  for i in range(len(exp_list)): # 2. LOOP FOR EVERY EXPERIMENTAL CONDITION\n",
        "    exp_trainT = shuffled_trainT[:, exp_list[i][0]]\n",
        "    print(\"train #\", exp_list[i][0])\n",
        "\n",
        "    # Only grab the appropriate experiment condition\n",
        "    exp_testT = shuffled_testT[:, exp_list[i][1]]\n",
        "    print(\"test #\", exp_list[i][1])\n",
        "\n",
        "    # Create Tensor Dataset\n",
        "    train_dataset = TensorDataset(shuffled_trainI, exp_trainT)\n",
        "    test_dataset = TensorDataset(shuffled_testI, exp_testT)\n",
        "\n",
        "    # Create Train loader\n",
        "    train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle=False)\n",
        "    test_loader = DataLoader(test_dataset, batch_size = batch_size, shuffle=False)\n",
        "\n",
        "    # Instantiate the model\n",
        "    model = Simple_Nonlin(input_dim, hidden_dim, output_dim) # so that you can only input 'model' not 'modelName'\n",
        "    optimizer = optim.Adam(model.parameters(), lr = learning_rate)\n",
        "\n",
        "    # All Losses Collection\n",
        "    trainLosses = []\n",
        "    valLosses = []\n",
        "    accuracies = []\n",
        "    sparsities = []\n",
        "    crossEntropyLosses = []\n",
        "    PR_losses = []\n",
        "    PR_connect_losses = []\n",
        "\n",
        "    for epoch in range(num_epochs): # 3. LOOP FOR EPOCH / COND\n",
        "\n",
        "      # Training Stage\n",
        "      model.train()\n",
        "\n",
        "      # losses\n",
        "      train_loss = 0\n",
        "      sparsity_loss = 0\n",
        "      crossEntropy_loss = 0\n",
        "      PR_loss = 0\n",
        "      PR_connect_loss = 0\n",
        "\n",
        "      for train_input, train_target in train_loader: # 4. LOOP FOR TRAIN BATCH\n",
        "\n",
        "        train_input = train_input.float()\n",
        "\n",
        "        # clear the gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Apply the model\n",
        "        x_h, train_output = model(train_input)\n",
        "\n",
        "        # # Take out the connectivity matrix\n",
        "        # connectivity_matrix = model.input_layer.weight.data\n",
        "        # PR_connect = PR_norm(connectivity_matrix)\n",
        "        # PR_connect_loss += PR_connect\n",
        "\n",
        "        # Compute sparsity from the hidden layer\n",
        "        sparsity = L1_norm(x_h)\n",
        "        sparsity_loss += sparsity\n",
        "\n",
        "        # Compute participation ratio from the hidden layer\n",
        "        PR = PR_norm(x_h)\n",
        "        PR_loss += PR\n",
        "\n",
        "        # <<Compute the total loss>>\n",
        "        CE_loss, loss = custom_loss(train_output, train_target, sparsity, beta1, beta2, PR, beta3) #PR_connect, beta4\n",
        "\n",
        "        # Add cross entropy loss\n",
        "        crossEntropy_loss += CE_loss\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "\n",
        "        # Update the weights\n",
        "        optimizer.step()\n",
        "\n",
        "        # Add train loss\n",
        "        train_loss += loss.item()\n",
        "\n",
        "      # Find the average loss across all batches for one epoch\n",
        "      avg_train_loss = train_loss / len(train_loader)\n",
        "      trainLosses.append(avg_train_loss)\n",
        "\n",
        "      avg_sparsity = sparsity_loss / len(train_loader)\n",
        "      sparsities.append(avg_sparsity)\n",
        "\n",
        "      avg_crossEntropy_loss = crossEntropy_loss/len(train_loader)\n",
        "      crossEntropyLosses.append(avg_crossEntropy_loss)\n",
        "\n",
        "      avg_PR_loss = PR_loss/len(train_loader)\n",
        "      PR_losses.append(avg_PR_loss)\n",
        "\n",
        "      avg_PR_connect_loss = PR_connect_loss/len(train_loader)\n",
        "      PR_connect_losses.append(avg_PR_connect_loss)\n",
        "\n",
        "      # Validation Stage\n",
        "      model.eval()\n",
        "      val_loss = 0\n",
        "      total = 0\n",
        "      correct = 0\n",
        "\n",
        "      with torch.no_grad():\n",
        "\n",
        "        for test_input, test_target in test_loader: # 5. LOOP FOR TEST BATCH\n",
        "\n",
        "          # test input\n",
        "          test_x_h, test_output = model(test_input)\n",
        "\n",
        "          # # Take out the connectivity matrix\n",
        "          # connectivity_matrix = model.input_layer.weight.data\n",
        "          # PR_connect = PR_norm(connectivity_matrix)\n",
        "\n",
        "          # Compute sparsity from the hidden layer\n",
        "          sparsity = L1_norm(x_h)\n",
        "\n",
        "          # Compute participation ratio from the hidden layer\n",
        "          PR = PR_norm(x_h)\n",
        "\n",
        "          # <<Compute the total loss>>\n",
        "          _, loss = custom_loss(train_output, train_target, sparsity, beta1, beta2, PR, beta3) # PR_connect, beta4\n",
        "\n",
        "          # Validation loss\n",
        "          val_loss += loss.item()\n",
        "\n",
        "          # Get the max output?\n",
        "          _, predicted = torch.max(test_output, 1)\n",
        "\n",
        "          # Store the accuracy\n",
        "          total += test_target.size(0)\n",
        "          correct += (predicted == test_target).sum().item()\n",
        "\n",
        "      accuracy = correct/total\n",
        "      accuracies.append(accuracy)\n",
        "\n",
        "      # Average validation loss for this epoch\n",
        "      avg_val_loss = val_loss / len(test_loader)\n",
        "      valLosses.append(avg_val_loss)\n",
        "\n",
        "      # if (epoch+1) % 1 == 0:\n",
        "      #   print(f'Epoch [{epoch+1}/{num_epochs}], Training Loss: {train_loss/len(train_loader):.4f}, Validation Loss: {val_loss/len(test_loader):.4f}')\n",
        "\n",
        "    ## These are all after epochs are finished.\n",
        "    ## These get added at the end of one experiment\n",
        "    avg_acc_per_exp = np.sum(accuracies)/num_epochs\n",
        "    print(\"avg_acc_per_exp\", avg_acc_per_exp)\n",
        "    total_accuracies[iter,i] = avg_acc_per_exp\n",
        "\n",
        "    # output of the hidden layer based on exp_testT\n",
        "    new_x_h, _ = model(shuffled_testI)\n",
        "    pca = PCA(n_components = 3)\n",
        "    new_x_h = new_x_h.detach().numpy()\n",
        "    transformed_Xh = pca.fit_transform(new_x_h)\n",
        "    pca_dict[i][iter,:,:] = transformed_Xh\n",
        "\n",
        "  end_time = time.time()  # End time for the epoch\n",
        "  epoch_time = end_time - start_time\n",
        "  print(f\"Epoch {epoch + 1} took {epoch_time} seconds\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "43QmTIeQMrhH"
      },
      "outputs": [],
      "source": [
        "# RESHAPE\n",
        "reshaped_total_acc = total_accuracies.reshape(iter_num, 3, 3)\n",
        "\n",
        "# FIND mean across iternums\n",
        "mean_total_acc = np.average(reshaped_total_acc, axis=0)\n",
        "\n",
        "# Display the mean total acc\n",
        "plt.imshow(mean_total_acc, aspect='auto', cmap='viridis')\n",
        "plt.colorbar(label='Mean Accuracy')  # Adding a color legend with label\n",
        "\n",
        "# Setting the tick labels for x and y axes\n",
        "plt.xticks(ticks=[0, 1, 2], labels=['1', '2', '3'])\n",
        "plt.yticks(ticks=[0, 1, 2], labels=['1', '2', '3'])\n",
        "\n",
        "# Adding labels to the axes\n",
        "plt.xlabel('Test')\n",
        "plt.ylabel('Train')\n",
        "plt.title('Mean Accuracy')\n",
        "\n",
        "# Annotate each cell with the numeric value\n",
        "for i in range(mean_total_acc.shape[0]):\n",
        "    for j in range(mean_total_acc.shape[1]):\n",
        "        plt.text(j, i, f'{mean_total_acc[i, j]:.2f}', ha='center', va='center', color='white', fontsize=14)\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sS0iLCb8NIPt"
      },
      "outputs": [],
      "source": [
        "# Mean PCA dictionary\n",
        "mean_pca_dict = {i: np.zeros((400, 3)) for i in range(len(exp_list))}\n",
        "for i in range(9):\n",
        "  mean_pca_dict[i] = np.mean(pca_dict[i], axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L_Y_2KLOyW16"
      },
      "outputs": [],
      "source": [
        "# Calculate the centroid\n",
        "four_points_dict = {i: np.zeros((4, 3)) for i in range(len(exp_list))}\n",
        "\n",
        "for i in range(9):\n",
        "  four_points_dict[i][0,:] = calculate_centroid(mean_pca_dict[i][:100,:])\n",
        "  four_points_dict[i][1,:] = calculate_centroid(mean_pca_dict[i][100:200,:])\n",
        "  four_points_dict[i][2,:] = calculate_centroid(mean_pca_dict[i][200:300,:])\n",
        "  four_points_dict[i][3,:] = calculate_centroid(mean_pca_dict[i][300:,:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qNNBZ0Uecruz"
      },
      "outputs": [],
      "source": [
        "# SHOW ALL THE POINTS\n",
        "fig, axs = plt.subplots(3, 3, figsize=(10,10), subplot_kw={'projection': '3d'})\n",
        "# Define colors for each subplot\n",
        "colors = ['r', 'g', 'b', 'k']\n",
        "\n",
        "subplot_titles = ['Train 1, Test 1', 'Train 1, Test 2', 'Train 1, Test 3',\n",
        "                  'Train 2, Test 1', 'Train 2, Test 2', 'Train 2, Test 3',\n",
        "                  'Train 3, Test 1', 'Train 3, Test 2', 'Train 3, Test 3']\n",
        "\n",
        "for i, ax in enumerate(axs.flat):\n",
        "    points = mean_pca_dict[i]\n",
        "    # Scatter plot the transformed data\n",
        "    for _, (idx, color) in enumerate(zip(range(4), ['r','g','b','k'])):\n",
        "        ax.scatter(points[idx*100:(idx+1)*100, 0],\n",
        "                  points[idx*100:(idx+1)*100, 1],\n",
        "                  points[idx*100:(idx+1)*100, 2],\n",
        "                  c=color, marker='o')\n",
        "\n",
        "\n",
        "    # Set labels and title (axis is important)\n",
        "    ax.set_xlabel('PC 1')\n",
        "    ax.set_ylabel('PC 2')\n",
        "    ax.set_zlabel('PC 3')\n",
        "    ax.set_title(subplot_titles[i])\n",
        "    ax.set_xlim([-15, 15])\n",
        "    ax.set_ylim([-15, 15])\n",
        "    ax.set_zlim([-15, 15])\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kHR-mas7wadE"
      },
      "outputs": [],
      "source": [
        "# Show the main centroid points\n",
        "fig, axs = plt.subplots(3, 3, figsize=(8,8), subplot_kw={'projection': '3d'})\n",
        "\n",
        "# Define colors for each subplot\n",
        "colors = ['r', 'g', 'b', 'k']\n",
        "\n",
        "# Plot each set of points in its respective subplot\n",
        "for i, ax in enumerate(axs.flat):\n",
        "    points = four_points_dict[i]\n",
        "    for j in range(4):\n",
        "        ax.scatter(points[j, 0], points[j, 1], points[j, 2],\n",
        "                   c=colors[j], marker='o', label=f'Point {j}')\n",
        "    ax.set_title(subplot_titles[i])\n",
        "    ax.set_xlabel('X')\n",
        "    ax.set_ylabel('Y')\n",
        "    ax.set_zlabel('Z')\n",
        "    # ax.set_xlim([-1, 1])\n",
        "    # ax.set_ylim([-1, 1])\n",
        "    # ax.set_zlim([-1, 1])\n",
        "    ax.legend()\n",
        "\n",
        "# Adjust layout\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p3rwO_w1w6TN"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMgyGTcZ4Z9ae/5hpufHG7K",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}